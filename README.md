# HILRecognizer
# Get Started

HILRecognizer contains code and datasets for KDD 2019 publication:

* **Zhang, S., He, L., Vucetic, S., Dragut, E., How to Invest my Time: Lessons from Human-in-the-Loop Entity Extraction, KDD, 2019**

To run the code, the following environment is required:
* python==2.7.6
* torch==0.3.1

# Run 5 fold cross validation. 
The 5-fold cross validation is used to select the best hyperparameters based on the weaklly labeled data, via ``random search`` technique. 
After the 5 fold cross validation, the best hyperparameter ``XX.pkl`` is output to the ``outfolder`` folder.

``
outfolder="experiments/position/kaggle_bound/pretrain"
CUDA_VISIBLE_DEVICES="$dev" 
``

``
python s_train_bilstm_tagger.py --data data/testDateTimeAll.csv \
--save "$outfolder" --pooling all --partition loo --epochs 5 --cuda --batch-size 512 \
--tags o y --max_len 104 --label R.E.tag.gr6
``


# Pretrain on weakly labeled data

Pretrain a deep model based on the weakly labeled data. Weak labels are generated by Regular Expressions.

``CUDA_VISIBLE_DEVICES="$dev" ``

``
python s_train_bilstm_tagger.py --data data/testDateTimeAll.csv \
--save experiments/position/kaggle_bound/pretrain \
--params experiments/position/kaggle_bound/loo_R.E.tag_best_args.pkl \
--epochs 5 --cuda --batch-size 512 --tags o y --max_len 104 --label R.E.tag --run pretrain
``

# Fine-tuninig pre-trained model with active learning

Fine-tune the pre-trained model with ``albs`` human labels each iteration.

aliter: active learning iterations \
albs: active learning batch size \
epoch: active learning epochs \
pretrain: pretrained model

``
aliter=50  albs=20  epoch=10 
best_args="loo_R.E.tag_best_args.pkl" 
pretrain= "R.E.tag_testKaggleAll_pretrain_5.pt" 
outfolder="active_learning_cv_by_outlet_retag_pt5"
``

``
CUDA_VISIBLE_DEVICES="$dev" 
``

``
python s_train_bilstm_tagger.py --data data/testDateTimeAll.csv \
--save experiments/position/kaggle_bound/"$outfolder"/ \
--params experiments/position/kaggle_bound/"$best_args" \
--pretrain experiments/position/kaggle_bound/pretrain/"$pretrain" \
--epochs 10 --cuda --partition outlet --batch-size 300 --tags o y --max_len 104 --label TagLabel \
--fold "$fold" --run al --al_bs "$albs" --al_iter "$aliter" 
``
